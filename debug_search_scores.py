"""
ê²€ìƒ‰ ì ìˆ˜ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ìœ ì‚¬ë„ê°€ 100%ë¥¼ ë„˜ëŠ” ë¬¸ì œ ë¶„ì„
"""

import os
import sys
from pathlib import Path

# PYTHONPATH ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent))

from openai import AzureOpenAI
from backend.shared.services.knowledge_base_loader import KnowledgeBaseLoader
from backend.consistency_agent.hybrid_searcher import HybridSearcher
from backend.consistency_agent.a3_node.article_matcher import ArticleMatcher


def debug_search_scores():
    """ê²€ìƒ‰ ì ìˆ˜ ë²”ìœ„ í™•ì¸"""
    
    # Azure OpenAI í´ë¼ì´ì–¸íŠ¸
    if not os.getenv('AZURE_OPENAI_API_KEY'):
        print("âŒ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ì—†ìŒ")
        return
    
    azure_client = AzureOpenAI(
        api_key=os.getenv('AZURE_OPENAI_API_KEY'),
        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),
        api_version="2024-02-01"
    )
    
    # KnowledgeBaseLoader
    kb_loader = KnowledgeBaseLoader()
    contract_type = "provide"
    
    # HybridSearcher ìƒì„±
    searcher = HybridSearcher(
        azure_client=azure_client,
        embedding_model="text-embedding-3-large"
    )
    
    # ì¸ë±ìŠ¤ ë¡œë“œ
    print(f"ğŸ“š ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘: {contract_type}")
    faiss_index = kb_loader.load_faiss_index(contract_type)
    chunks = kb_loader.load_chunks(contract_type)
    whoosh_indexer = kb_loader.load_whoosh_index(contract_type)
    
    if not faiss_index or not chunks or not whoosh_indexer:
        print("âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    searcher.load_indexes(faiss_index, chunks, whoosh_indexer)
    print(f"âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ë°ì´í„° ì œê³µ ë²”ìœ„ ë° ë°©ì‹",
        "ê³„ì•½ì˜ ëª©ì ",
        "ë°ì´í„° ì´ìš© ëª©ì  ë° ë²”ìœ„",
        "ë°ì´í„° ì œê³µ ê¸°ê°„",
        "ë¹„ë°€ìœ ì§€ ì˜ë¬´"
    ]
    
    print("\n" + "="*80)
    print("ê²€ìƒ‰ ì ìˆ˜ ë¶„ì„")
    print("="*80)
    
    for query in test_queries:
        print(f"\nğŸ” ì¿¼ë¦¬: {query}")
        print("-" * 80)
        
        # Dense ê²€ìƒ‰
        dense_results = searcher.dense_search(query, top_k=10)
        print(f"\n  [Dense ê²€ìƒ‰] {len(dense_results)}ê°œ ê²°ê³¼")
        if dense_results:
            scores = [r['score'] for r in dense_results]
            print(f"    ì ìˆ˜ ë²”ìœ„: {min(scores):.4f} ~ {max(scores):.4f}")
            print(f"    Top-3:")
            for i, r in enumerate(dense_results[:3], 1):
                print(f"      {i}. {r['chunk'].get('parent_id', 'N/A')} - {r['score']:.4f}")
        
        # Sparse ê²€ìƒ‰
        sparse_results = searcher.sparse_search(query, top_k=10)
        print(f"\n  [Sparse ê²€ìƒ‰] {len(sparse_results)}ê°œ ê²°ê³¼")
        if sparse_results:
            scores = [r['score'] for r in sparse_results]
            print(f"    ì ìˆ˜ ë²”ìœ„: {min(scores):.4f} ~ {max(scores):.4f}")
            print(f"    Top-3:")
            for i, r in enumerate(sparse_results[:3], 1):
                print(f"      {i}. {r['chunk'].get('parent_id', 'N/A')} - {r['score']:.4f}")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        hybrid_results = searcher.search(query, top_k=10)
        print(f"\n  [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰] {len(hybrid_results)}ê°œ ê²°ê³¼")
        if hybrid_results:
            scores = [r['score'] for r in hybrid_results]
            print(f"    ì ìˆ˜ ë²”ìœ„: {min(scores):.4f} ~ {max(scores):.4f}")
            print(f"    Top-3:")
            for i, r in enumerate(hybrid_results[:3], 1):
                dense_score = r.get('dense_score', 0.0)
                sparse_score = r.get('sparse_score', 0.0)
                final_score = r['score']
                print(f"      {i}. {r.get('parent_id', 'N/A')} - Final: {final_score:.4f} (Dense: {dense_score:.4f}, Sparse: {sparse_score:.4f})")
                
                # 100% ì´ˆê³¼ ì—¬ë¶€ í™•ì¸
                if final_score > 1.0:
                    print(f"        âš ï¸  ì ìˆ˜ê°€ 1.0ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
    
    print("\n" + "="*80)
    print("ArticleMatcher í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # ArticleMatcher í…ŒìŠ¤íŠ¸
    matcher = ArticleMatcher(
        knowledge_base_loader=kb_loader,
        azure_client=azure_client,
        similarity_threshold=0.7
    )
    
    test_article = {
        "number": "5",
        "title": "ë°ì´í„° ì œê³µ ë²”ìœ„ ë° ë°©ì‹",
        "content": [
            "ì œê³µìëŠ” ì´ìš©ìì—ê²Œ ë‹¤ìŒ ê° í˜¸ì˜ ë°ì´í„°ë¥¼ ì œê³µí•œë‹¤.",
            "1. ë°ì´í„°ì˜ ì¢…ë¥˜: ê³ ê° ê±°ë˜ ë°ì´í„°",
            "2. ë°ì´í„°ì˜ í˜•ì‹: CSV íŒŒì¼",
            "3. ì œê³µ ë°©ì‹: APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì œê³µ"
        ]
    }
    
    print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¡°í•­: ì œ{test_article['number']}ì¡° ({test_article['title']})")
    print("-" * 80)
    
    matching_result = matcher.find_matching_article(
        test_article,
        contract_type,
        top_k=5
    )
    
    print(f"\n  ë§¤ì¹­ ê²°ê³¼:")
    print(f"    - ë§¤ì¹­ ì„±ê³µ: {matching_result['matched']}")
    print(f"    - ìœ ì‚¬ë„: {matching_result['similarity']:.4f}")
    if matching_result['similarity'] > 1.0:
        print(f"      âš ï¸  ìœ ì‚¬ë„ê°€ 1.0ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
    print(f"    - í‘œì¤€ ì¡°í•­: {matching_result.get('std_article_id', 'N/A')}")
    print(f"    - í‘œì¤€ ì œëª©: {matching_result.get('std_article_title', 'N/A')}")
    
    # í•˜ìœ„í•­ëª©ë³„ ê²°ê³¼
    sub_item_results = matching_result.get('sub_item_results', [])
    if sub_item_results:
        print(f"\n  í•˜ìœ„í•­ëª©ë³„ Top-1 ê²°ê³¼:")
        for sub_result in sub_item_results:
            idx = sub_result['sub_item_index']
            score = sub_result['score']
            parent_id = sub_result.get('parent_id', 'N/A')
            print(f"    {idx}. {parent_id} - {score:.4f}")
            if score > 1.0:
                print(f"       âš ï¸  ì ìˆ˜ê°€ 1.0ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    debug_search_scores()
