import sys
from pathlib import Path
sys.path.append('/app')

from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.responses import JSONResponse, FileResponse
from sqlalchemy.orm import Session
import logging
import json
import uuid
from datetime import datetime
import time

logger = logging.getLogger("uvicorn.error")

from backend.fastapi.user_contract_parser import UserContractParser
from backend.shared.database import init_db, get_db, ContractDocument, ClassificationResult
from backend.classification_agent.agent import classify_contract_task

app = FastAPI()


# ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    init_db()
    logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    try:
        from backend.shared.services import get_knowledge_base_loader
        loader = get_knowledge_base_loader()
        status = loader.verify_knowledge_base()
        
        logger.info(f"ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ: {status['status']}")
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ê³„ì•½ ìœ í˜•: {status['available_types']}")
        
        if status['missing_types']:
            logger.warning(f"ëˆ„ë½ëœ ê³„ì•½ ìœ í˜•: {status['missing_types']}")
            logger.warning("ingestion CLIë¥¼ ì‹¤í–‰í•˜ì—¬ ì§€ì‹ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
    except Exception as e:
        logger.error(f"ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")


@app.get("/")
async def root():
    return {"message": "FastAPI ì„œë²„ ì‹¤í–‰ ì¤‘"}


@app.get("/api/knowledge-base/status")
async def knowledge_base_status():
    """
    ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    
    Returns:
        {
            "status": "ok" | "incomplete" | "missing",
            "available_types": [...],
            "missing_types": [...],
            "details": {...}
        }
    """
    try:
        from backend.shared.services import get_knowledge_base_loader
        
        loader = get_knowledge_base_loader()
        status = loader.verify_knowledge_base()
        
        return status
        
    except Exception as e:
        logger.exception(f"ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _temp_file_path(filename: str) -> Path:
    """ì„ì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
    base = Path("/tmp/uploads")
    base.mkdir(parents=True, exist_ok=True)
    return base / filename


@app.post("/upload")
async def upload_file(file: UploadFile = File(...), db: Session = Depends(get_db)):
    """
    ì‚¬ìš©ì ê³„ì•½ì„œ DOCX ì—…ë¡œë“œ ë° ì „ì²´ ì²˜ë¦¬ (íŒŒì‹± â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ ë¶„ë¥˜)
    
    Args:
        file: ì—…ë¡œë“œëœ DOCX íŒŒì¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        {
            "success": bool,
            "filename": str,
            "contract_id": str,
            "chunks_count": int,
            "metadata": dict,
            "message": str
        }
    """
    try:
        filename = Path(file.filename).name
        
        # DOCX íŒŒì¼ë§Œ í—ˆìš©
        if not filename.lower().endswith('.docx'):
            raise HTTPException(status_code=400, detail="DOCX íŒŒì¼ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")

        # contract_id ìƒì„±
        contract_id = f"contract_{uuid.uuid4().hex[:12]}"
        
        # íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        save_dir = Path("/app/data/source_documents")
        save_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_filename = f"user_contract_{timestamp}.docx"
        saved_path = save_dir / saved_filename
        
        # íŒŒì¼ ì €ì¥
        content = await file.read()
        with open(saved_path, 'wb') as f:
            f.write(content)
        
        logger.info(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {saved_path}")

        # UserContractProcessor ì´ˆê¸°í™”
        from backend.fastapi.user_contract_parser import UserContractParser
        from backend.shared.services.user_contract_chunker import UserContractChunker
        from backend.shared.services.user_contract_embedder import UserContractEmbedder
        from backend.shared.services.user_contract_processor import UserContractProcessor
        from backend.shared.services import get_embedding_service
        
        parser = UserContractParser()
        chunker = UserContractChunker()
        embedding_service = get_embedding_service()
        embedder = UserContractEmbedder(embedding_service)
        processor = UserContractProcessor(parser, chunker, embedder)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬
        output_dir = Path("/app/data/user_contracts") / contract_id
        output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ì²˜ë¦¬ ì‹œì‘: {contract_id}")
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (íŒŒì‹± â†’ ì²­í‚¹ â†’ ì„ë² ë”©)
        process_result = processor.process_contract(
            docx_path=saved_path,
            output_dir=output_dir,
            contract_id=contract_id
        )
        
        if not process_result["success"]:
            raise HTTPException(
                status_code=500,
                detail=f"ì²˜ë¦¬ ì‹¤íŒ¨: {process_result.get('error', 'Unknown error')}"
            )
        
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {contract_id}, {process_result['metadata']['total_chunks']}ê°œ ì²­í¬")
        
        # DBì— ì €ì¥
        contract_doc = ContractDocument(
            contract_id=contract_id,
            filename=filename,
            file_path=str(saved_path),
            parsed_data=None,  # chunks.json ê²½ë¡œë¡œ ëŒ€ì²´
            parsed_metadata={
                "chunks_path": process_result["chunks_path"],
                "embeddings_path": process_result["embeddings_path"],
                **process_result["metadata"]
            },
            status="processed"
        )
        db.add(contract_doc)
        db.commit()
        
        logger.info(f"DB ì €ì¥ ì™„ë£Œ: {contract_id}")

        # Celeryë¥¼ í†µí•´ ë¶„ë¥˜ ì‘ì—…ì„ íì— ì „ì†¡
        try:
            task = classify_contract_task.delay(contract_id)
            logger.info(f"ë¶„ë¥˜ ì‘ì—… íì— ì „ì†¡: {contract_id}, Task ID: {task.id}")

            # ê³„ì•½ì„œ ìƒíƒœë¥¼ classifyingìœ¼ë¡œ ì—…ë°ì´íŠ¸
            contract_doc.status = "classifying"
            db.commit()

        except Exception as e:
            logger.error(f"ë¶„ë¥˜ ì‘ì—… í ì „ì†¡ ì‹¤íŒ¨: {e}")

        return JSONResponse(
            content={
                "success": True,
                "filename": filename,
                "contract_id": contract_id,
                "chunks_count": process_result["metadata"]["total_chunks"],
                "parsed_metadata": process_result["metadata"],
                "structured_data": process_result.get("structured_data", {}),
                "metadata": process_result["metadata"],
                "message": "ì²˜ë¦¬ ì™„ë£Œ. ë¶„ë¥˜ ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤."
            },
            media_type="application/json; charset=utf-8"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/upload-simple")
async def upload_file_simple(file: UploadFile = File(...)):
    """
    ê°„ë‹¨í•œ íŒŒì¼ ì—…ë¡œë“œ ë° íŒŒì‹± (PDF, DOCX, TXT ì§€ì›, DB ì €ì¥ ì—†ìŒ)
    
    Args:
        file: ì—…ë¡œë“œëœ íŒŒì¼
        
    Returns:
        {
            "success": bool,
            "filename": str,
            "file_type": str,
            "size_bytes": int,
            "text": str (ë˜ëŠ” íŒŒì‹± ê²°ê³¼)
        }
    """
    try:
        filename = Path(file.filename).name
        file_ext = filename.lower().split('.')[-1]
        
        # ì§€ì› í˜•ì‹ í™•ì¸
        if file_ext not in ['pdf', 'docx', 'txt']:
            raise HTTPException(
                status_code=400, 
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (ì§€ì›: PDF, DOCX, TXT)"
            )

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = _temp_file_path(filename)
        content = await file.read()
        
        # íŒŒì¼ ì €ì¥
        with open(temp_path, 'wb') as f:
            f.write(content)

        # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬
        result = {}
        
        if file_ext == 'pdf':
            # PyMuPDF íŒŒì‹±
            try:
                import fitz  # PyMuPDF
                doc = fitz.open(str(temp_path))
                text_parts = []
                for page in doc:
                    text_parts.append(page.get_text())
                text = "\n".join(text_parts)
                doc.close()
                result["text"] = text
                result["pages"] = len(doc)
            except ImportError:
                raise HTTPException(
                    status_code=500,
                    detail="PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ PyMuPDFê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )
        
        elif file_ext == 'docx':
            # DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ
            try:
                from docx import Document
                doc = Document(str(temp_path))
                text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
                result["text"] = text
                result["paragraphs"] = len([p for p in doc.paragraphs if p.text.strip()])
            except ImportError:
                raise HTTPException(
                    status_code=500, 
                    detail="DOCX ì²˜ë¦¬ë¥¼ ìœ„í•´ python-docxê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )
        
        elif file_ext == 'txt':
            # TXT íŒŒì¼ ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
            encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']
            text = None
            used_encoding = None
            
            for encoding in encodings:
                try:
                    with open(temp_path, 'r', encoding=encoding) as f:
                        text = f.read()
                    used_encoding = encoding
                    break
                except UnicodeDecodeError:
                    continue
            
            if text is None:
                raise HTTPException(
                    status_code=400,
                    detail=f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ì¸ì½”ë”©: {', '.join(encodings)}"
                )
            
            result["text"] = text
            result["lines"] = len(text.split('\n'))
            result["encoding"] = used_encoding

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            temp_path.unlink()
        except Exception as e:
            logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

        return {
            "success": True,
            "filename": filename,
            "file_type": file_ext,
            "size_bytes": len(content),
            **result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/verify")
async def verify_contract(file: UploadFile = File(...), contract_type: str = "provide"):
    """
    ê³„ì•½ì„œ ì—…ë¡œë“œ ë° ìë™ ê²€ì¦
    
    Args:
        file: ì—…ë¡œë“œëœ ê³„ì•½ì„œ íŒŒì¼ (TXT, DOCX, PDF)
        contract_type: ê³„ì•½ì„œ ìœ í˜• (provide, create, process, brokerage_provider, brokerage_user)
    
    Returns:
        ê²€ì¦ ê²°ê³¼ ìš”ì•½ ë° ë¦¬í¬íŠ¸ ê²½ë¡œ
    """
    try:
        start_time = time.time()
        
        filename = Path(file.filename).name
        file_ext = filename.lower().split('.')[-1]
        
        # ì§€ì› í˜•ì‹ í™•ì¸
        if file_ext not in ['txt', 'docx', 'pdf']:
            raise HTTPException(
                status_code=400,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (ì§€ì›: TXT, DOCX, PDF)"
            )
        
        logger.info(f"[Verify] íŒŒì¼ ì—…ë¡œë“œ: {filename}")
        
        # íŒŒì¼ ì €ì¥
        save_dir = Path("/app/data/source_documents")
        save_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_filename = f"user_contract_{timestamp}.{file_ext}"
        saved_path = save_dir / saved_filename
        
        content = await file.read()
        with open(saved_path, 'wb') as f:
            f.write(content)
        
        logger.info(f"[Verify] íŒŒì¼ ì €ì¥: {saved_path}")
        
        # ê²€ì¦ ì‹¤í–‰
        logger.info(f"[Verify] ê²€ì¦ ì‹œì‘... (ê³„ì•½ ìœ í˜•: {contract_type})")
        result = _run_verification_api(str(saved_path), contract_type)
        
        execution_time = time.time() - start_time
        
        logger.info(f"[Verify] ê²€ì¦ ì™„ë£Œ ({execution_time:.2f}s)")
        
        return {
            "success": True,
            "filename": filename,
            "report_id": result["report_id"],
            "report_path": result["report_path"],
            "verification_summary": {
                "total_standard_clauses": result["total_standard_clauses"],
                "total_user_clauses": result["total_user_clauses"],
                "matched_clauses": result["matched_clauses"],
                "missing_clauses": result["missing_count"],
                "compliance_rate": result["verification_rate"]
            },
            "execution_time": execution_time
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Verify] ê²€ì¦ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}")


def _run_verification_api(user_contract_path: str, contract_type: str = "provide"):
    """
    APIìš© ê²€ì¦ ì‹¤í–‰ í•¨ìˆ˜ (ingestion/ingest.pyì˜ _run_verification ë¡œì§ ì¬ì‚¬ìš©)
    
    Args:
        user_contract_path: ì‚¬ìš©ì ê³„ì•½ì„œ íŒŒì¼ ê²½ë¡œ
        contract_type: ê³„ì•½ì„œ ìœ í˜• (provide, create, process, brokerage_provider, brokerage_user)
    
    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    from backend.clause_verification.node_1_clause_matching.data_loader import ContractDataLoader
    from backend.clause_verification.node_1_clause_matching.verification_engine import ContractVerificationEngine
    from backend.clause_verification.node_1_clause_matching.hybrid_search import HybridSearchEngine
    from backend.clause_verification.node_1_clause_matching.llm_verification import LLMVerificationService
    from backend.shared.services import get_embedding_service
    
    # ê³„ì•½ ìœ í˜•ë³„ í‘œì¤€ ê³„ì•½ì„œ ë§¤í•‘
    contract_type_mapping = {
        "provide": "provide_std_contract_chunks.json",
        "create": "create_std_contract_chunks.json",
        "process": "process_std_contract_chunks.json",
        "brokerage_provider": "brokerage_provider_std_contract_chunks.json",
        "brokerage_user": "brokerage_user_std_contract_chunks.json"
    }
    
    # í‘œì¤€ ê³„ì•½ì„œ ê²½ë¡œ
    standard_filename = contract_type_mapping.get(contract_type, "provide_std_contract_chunks.json")
    standard_contract_path = f"/app/data/chunked_documents/{standard_filename}"
    
    if not Path(standard_contract_path).exists():
        raise FileNotFoundError(f"í‘œì¤€ ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {standard_contract_path}")
    
    if not Path(user_contract_path).exists():
        raise FileNotFoundError(f"ì‚¬ìš©ì ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_contract_path}")
    
    logger.info("[Verify] 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ")
    
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    loader = ContractDataLoader()
    
    # í‘œì¤€ ê³„ì•½ì„œ ë¡œë“œ (KnowledgeBaseLoader ì‚¬ìš©)
    standard_clauses = loader.load_standard_contract(
        contract_type=contract_type,
        use_knowledge_base=True
    )
    logger.info(f"[Verify] í‘œì¤€ ê³„ì•½ì„œ ë¡œë“œ: {len(standard_clauses)}ê°œ ì¡°ë¬¸ (ìœ í˜•: {contract_type})")
    
    # ì‚¬ìš©ì ê³„ì•½ì„œ ë¡œë“œ (íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬)
    file_ext = Path(user_contract_path).suffix.lower()
    
    if file_ext == '.txt':
        # TXT íŒŒì¼: ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin-1']
        user_text = None
        for encoding in encodings:
            try:
                with open(user_contract_path, 'r', encoding=encoding) as f:
                    user_text = f.read()
                logger.info(f"[Verify] íŒŒì¼ ì¸ì½”ë”© ê°ì§€: {encoding}")
                break
            except (UnicodeDecodeError, LookupError):
                continue
        
        if user_text is None:
            raise ValueError(f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ì¸ì½”ë”©: {', '.join(encodings)}")
    
    elif file_ext == '.docx':
        # DOCX íŒŒì¼: python-docx ì‚¬ìš©
        try:
            from docx import Document
            doc = Document(user_contract_path)
            paragraphs = [para.text for para in doc.paragraphs if para.text.strip()]
            user_text = "\n".join(paragraphs)
            logger.info(f"[Verify] DOCX íŒŒì¼ ì²˜ë¦¬: {len(paragraphs)}ê°œ ë¬¸ë‹¨")
        except ImportError:
            raise ImportError("DOCX ì²˜ë¦¬ë¥¼ ìœ„í•´ python-docxê°€ í•„ìš”í•©ë‹ˆë‹¤")
    
    elif file_ext == '.pdf':
        # PDF íŒŒì¼: PyMuPDF ì‚¬ìš©
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(user_contract_path)
            text_parts = []
            for page in doc:
                text_parts.append(page.get_text())
            user_text = "\n".join(text_parts)
            doc.close()
            logger.info(f"[Verify] PDF íŒŒì¼ ì²˜ë¦¬: {len(doc)}í˜ì´ì§€")
        except ImportError:
            raise ImportError("PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ PyMuPDFê°€ í•„ìš”í•©ë‹ˆë‹¤")
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
    
    if not user_text or not user_text.strip():
        raise ValueError("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    user_clauses = loader.load_user_contract_chunked(user_text)
    logger.info(f"[Verify] ì‚¬ìš©ì ê³„ì•½ì„œ ë¡œë“œ: {len(user_clauses)}ê°œ ì²­í¬")
    
    logger.info("[Verify] 2ë‹¨ê³„: ê²€ì¦ ì—”ì§„ ì´ˆê¸°í™”")
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    embedding_service = get_embedding_service()
    hybrid_search = HybridSearchEngine()  # ì—­ë°©í–¥ ê²€ì¦ì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨
    llm_verification = LLMVerificationService()
    
    # ê²€ì¦ ì—”ì§„ ì´ˆê¸°í™”
    engine = ContractVerificationEngine(
        embedding_service=embedding_service,
        hybrid_search=hybrid_search,
        llm_verification=llm_verification
    )
    
    logger.info("[Verify] 3ë‹¨ê³„: ê³„ì•½ì„œ ê²€ì¦ ìˆ˜í–‰")
    
    # ê²€ì¦ ìˆ˜í–‰
    result = engine.verify_contract_reverse(
        standard_clauses=standard_clauses,
        user_clauses=user_clauses,
        top_k_candidates=10,
        top_k_titles=5,
        min_confidence=0.5
    )
    
    logger.info(f"[Verify] ê²€ì¦ ì™„ë£Œ - ë§¤ì¹­: {result.matched_clauses}/{result.total_user_clauses}")
    
    logger.info("[Verify] 4ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„±")
    
    # ë³´ê³ ì„œ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = Path(f"/app/data/reports/verification_report_{timestamp}.txt")
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ê°„ë‹¨í•œ ë³´ê³ ì„œ ìƒì„±
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*100 + "\n")
        f.write("ê³„ì•½ì„œ ê²€ì¦ ë³´ê³ ì„œ\n")
        f.write("="*100 + "\n\n")
        f.write(f"ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½\n")
        f.write("-" * 50 + "\n")
        f.write(f"í‘œì¤€ ì¡°ë¬¸ ìˆ˜: {result.total_standard_clauses}ê°œ\n")
        f.write(f"ì‚¬ìš©ì ì²­í¬ ìˆ˜: {result.total_user_clauses}ê°œ\n")
        f.write(f"ë§¤ì¹­ëœ ì²­í¬: {result.matched_clauses}ê°œ\n")
        f.write(f"ëˆ„ë½ëœ ì¡°ë¬¸: {result.missing_count}ê°œ\n")
        f.write(f"ê²€ì¦ ì™„ë£Œìœ¨: {result.verification_rate:.1f}%\n\n")
        
        # ë§¤ì¹­ëœ ì¡°ë¬¸
        if result.match_results:
            f.write("âœ… ë§¤ì¹­ëœ ì¡°ë¬¸\n")
            f.write("-" * 50 + "\n")
            for match in [m for m in result.match_results if m.is_matched]:
                f.write(f"[{match.standard_clause.id}] {match.standard_clause.title}\n")
                f.write(f"  â† {match.matched_clause.title}\n")
                if match.llm_decision:
                    f.write(f"  ì‹ ë¢°ë„: {match.llm_decision.confidence:.0%}\n")
                f.write("\n")
        
        # ëˆ„ë½ëœ ì¡°ë¬¸
        if result.missing_clauses:
            f.write("\nâŒ ëˆ„ë½ëœ ì¡°ë¬¸\n")
            f.write("-" * 50 + "\n")
            for clause in result.missing_clauses:
                f.write(f"[{clause.id}] {clause.title}\n")
                f.write(f"  {clause.text[:100]}...\n\n")
    
    logger.info(f"[Verify] ë³´ê³ ì„œ ì €ì¥: {report_path}")
    
    return {
        "report_id": timestamp,
        "report_path": str(report_path),
        "total_standard_clauses": result.total_standard_clauses,
        "total_user_clauses": result.total_user_clauses,
        "matched_clauses": result.matched_clauses,
        "missing_count": result.missing_count,
        "verification_rate": result.verification_rate
    }


@app.get("/report/{report_id}")
async def download_report(report_id: str):
    """
    ê²€ì¦ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ
    
    Args:
        report_id: ë¦¬í¬íŠ¸ ID (íƒ€ì„ìŠ¤íƒ¬í”„)
    
    Returns:
        FileResponse: ë¦¬í¬íŠ¸ íŒŒì¼
    """
    try:
        report_path = Path(f"/app/data/reports/verification_report_{report_id}.txt")
        
        if not report_path.exists():
            raise HTTPException(status_code=404, detail="ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return FileResponse(
            path=str(report_path),
            media_type="text/plain",
            filename=f"verification_report_{report_id}.txt"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/classification/{contract_id}/start")
async def start_classification(contract_id: str, db: Session = Depends(get_db)):
    """
    ê³„ì•½ì„œ ë¶„ë¥˜ ì‹œì‘ (ìˆ˜ë™ íŠ¸ë¦¬ê±°)

    Args:
        contract_id: ê³„ì•½ì„œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        {
            "success": bool,
            "contract_id": str,
            "task_id": str,
            "message": str
        }
    """
    try:
        # ê³„ì•½ì„œ ì¡°íšŒ
        contract = db.query(ContractDocument).filter(
            ContractDocument.contract_id == contract_id
        ).first()

        if not contract:
            raise HTTPException(status_code=404, detail="ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        if not contract.parsed_data:
            raise HTTPException(status_code=400, detail="íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        # Celery Task íì— ì „ì†¡
        task = classify_contract_task.delay(contract_id)

        # ê³„ì•½ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
        contract.status = "classifying"
        db.commit()

        logger.info(f"ë¶„ë¥˜ ì‘ì—… íì— ì „ì†¡: {contract_id}, Task ID: {task.id}")

        return {
            "success": True,
            "contract_id": contract_id,
            "task_id": task.id,
            "message": "ë¶„ë¥˜ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/classification/{contract_id}ë¡œ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ì„¸ìš”."
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ë¶„ë¥˜ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/classification/{contract_id}")
async def get_classification(contract_id: str, db: Session = Depends(get_db)):
    """
    ë¶„ë¥˜ ê²°ê³¼ ì¡°íšŒ

    Args:
        contract_id: ê³„ì•½ì„œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        ë¶„ë¥˜ ê²°ê³¼
    """
    try:
        classification = db.query(ClassificationResult).filter(
            ClassificationResult.contract_id == contract_id
        ).first()

        if not classification:
            raise HTTPException(status_code=404, detail="ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return {
            "contract_id": classification.contract_id,
            "predicted_type": classification.predicted_type,
            "confidence": classification.confidence,
            "scores": classification.scores,
            "confirmed_type": classification.confirmed_type,
            "user_override": classification.user_override
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ë¶„ë¥˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/classification/{contract_id}/confirm")
async def confirm_classification(
    contract_id: str,
    confirmed_type: str,
    db: Session = Depends(get_db)
):
    """
    ì‚¬ìš©ìê°€ ë¶„ë¥˜ ìœ í˜• í™•ì¸/ìˆ˜ì •

    Args:
        contract_id: ê³„ì•½ì„œ ID
        confirmed_type: ì‚¬ìš©ìê°€ í™•ì¸í•œ ìœ í˜•
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        {
            "success": bool,
            "contract_id": str,
            "confirmed_type": str
        }
    """
    try:
        classification = db.query(ClassificationResult).filter(
            ClassificationResult.contract_id == contract_id
        ).first()

        if not classification:
            raise HTTPException(status_code=404, detail="ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ì‚¬ìš©ìê°€ ë³€ê²½í•œ ê²½ìš° ê¸°ë¡
        if confirmed_type != classification.predicted_type:
            classification.user_override = confirmed_type

        classification.confirmed_type = confirmed_type

        # ê³„ì•½ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
        contract = db.query(ContractDocument).filter(
            ContractDocument.contract_id == contract_id
        ).first()

        if contract:
            contract.status = "classified_confirmed"

        db.commit()

        logger.info(f"ë¶„ë¥˜ í™•ì¸: {contract_id} -> {confirmed_type}")

        return {
            "success": True,
            "contract_id": contract_id,
            "confirmed_type": confirmed_type
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ë¶„ë¥˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)


@app.post("/api/consistency/{contract_id}/start")
async def start_consistency_verification(contract_id: str, db: Session = Depends(get_db)):
    """
    ì •í•©ì„± ê²€ì¦ ì‹œì‘
    
    Args:
        contract_id: ê³„ì•½ì„œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        {
            "success": bool,
            "contract_id": str,
            "task_id": str
        }
    """
    try:
        # ê³„ì•½ì„œ í™•ì¸
        contract = db.query(ContractDocument).filter(
            ContractDocument.contract_id == contract_id
        ).first()
        
        if not contract:
            raise HTTPException(status_code=404, detail="ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë¶„ë¥˜ ê²°ê³¼ í™•ì¸
        classification = db.query(ClassificationResult).filter(
            ClassificationResult.contract_id == contract_id
        ).first()
        
        if not classification or not classification.confirmed_type:
            raise HTTPException(status_code=400, detail="ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ê²€ì¦ ì‘ì—… íì— ì „ì†¡
        from backend.consistency_agent.agent import verify_contract_task
        task = verify_contract_task.delay(contract_id)
        
        # ê³„ì•½ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
        contract.status = "verifying"
        db.commit()
        
        logger.info(f"ì •í•©ì„± ê²€ì¦ ì‹œì‘: {contract_id}, Task ID: {task.id}")
        
        return {
            "success": True,
            "contract_id": contract_id,
            "task_id": task.id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì •í•©ì„± ê²€ì¦ ì‹œì‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/consistency/{contract_id}")
async def get_consistency_result(contract_id: str, db: Session = Depends(get_db)):
    """
    ì •í•©ì„± ê²€ì¦ ê²°ê³¼ ì¡°íšŒ
    
    Args:
        contract_id: ê³„ì•½ì„œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        ê²€ì¦ ê²°ê³¼ ë˜ëŠ” ì§„í–‰ ìƒíƒœ
    """
    try:
        contract = db.query(ContractDocument).filter(
            ContractDocument.contract_id == contract_id
        ).first()
        
        if not contract:
            raise HTTPException(status_code=404, detail="ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return {
            "contract_id": contract_id,
            "status": contract.status,
            "result": contract.verification_result if hasattr(contract, 'verification_result') else None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì •í•©ì„± ê²€ì¦ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/consistency/{contract_id}/report")
async def get_verification_report(contract_id: str, db: Session = Depends(get_db)):
    """
    ê²€ì¦ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¡œ ë°˜í™˜
    
    Args:
        contract_id: ê³„ì•½ì„œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
    """
    try:
        from backend.consistency_agent.node_1_clause_matching.data_loader import ContractDataLoader
        from backend.consistency_agent.node_1_clause_matching.verifier import ContractVerificationEngine
        from backend.consistency_agent.node_1_clause_matching.hybrid_search import HybridSearchEngine
        from backend.consistency_agent.node_1_clause_matching.llm_verification import LLMVerificationService
        from backend.shared.services.embedding_service import EmbeddingService
        from backend.shared.database import ClassificationResult
        import json
        
        # ê³„ì•½ì„œ ì¡°íšŒ
        contract = db.query(ContractDocument).filter(
            ContractDocument.contract_id == contract_id
        ).first()
        
        if not contract:
            raise HTTPException(status_code=404, detail="ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if contract.status != "verified":
            raise HTTPException(status_code=400, detail=f"ê²€ì¦ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {contract.status}")
        
        # ë¶„ë¥˜ ê²°ê³¼ ì¡°íšŒ
        classification = db.query(ClassificationResult).filter(
            ClassificationResult.contract_id == contract_id
        ).first()
        
        contract_type = classification.confirmed_type or classification.predicted_type
        chunks_path = contract.parsed_metadata.get("chunks_path")
        
        # ê²€ì¦ ì¬ì‹¤í–‰
        loader = ContractDataLoader()
        embedding_service = EmbeddingService()
        hybrid_search = HybridSearchEngine()
        llm_verification = LLMVerificationService()
        verifier = ContractVerificationEngine(
            embedding_service=embedding_service,
            hybrid_search=hybrid_search,
            llm_verification=llm_verification,
            data_loader=loader
        )
        
        standard_clauses = loader.load_standard_contract(
            contract_type=contract_type,
            use_knowledge_base=True
        )
        
        with open(chunks_path, 'r', encoding='utf-8') as f:
            user_chunks = json.load(f)
        
        from backend.consistency_agent.node_1_clause_matching.models import ClauseData
        user_clauses = [
            ClauseData(
                id=chunk['id'],
                title=chunk.get('title', ''),
                subtitle=None,
                type=chunk.get('unit_type', 'article'),
                text=chunk.get('text_raw', ''),
                text_norm=chunk.get('text_norm', ''),
                breadcrumb=chunk.get('title', ''),
                embedding=chunk.get('embedding')
            )
            for chunk in user_chunks
        ]
        
        result = verifier.verify_contract_reverse(
            standard_clauses=standard_clauses,
            user_clauses=user_clauses
        )
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ê³„ì•½ì„œ ê²€ì¦ ê²°ê³¼")
        report_lines.append("=" * 80)
        report_lines.append(f"\nê³„ì•½ì„œ ID: {contract_id}")
        report_lines.append(f"ê³„ì•½ ìœ í˜•: {contract_type}")
        report_lines.append(f"\nê²€ì¦ ê²°ê³¼:")
        report_lines.append(f"  - í‘œì¤€ ì¡°ë¬¸: {result.total_standard_clauses}ê°œ")
        report_lines.append(f"  - ì‚¬ìš©ì ì²­í¬: {result.total_user_clauses}ê°œ")
        report_lines.append(f"  - ë§¤ì¹­ë¨: {result.matched_clauses}ê°œ")
        report_lines.append(f"  - ëˆ„ë½ë¨: {result.missing_count}ê°œ")
        report_lines.append(f"  - ê²€ì¦ìœ¨: {result.verification_rate:.1f}%")
        report_lines.append(f"\n{'='*80}\n")
        
        # ë§¤ì¹­ëœ ì¡°ë¬¸
        report_lines.append("âœ… ë§¤ì¹­ëœ ì¡°ë¬¸:")
        for match in [m for m in result.match_results if m.is_matched]:
            report_lines.append(f"\n  [{match.standard_clause.id}] {match.standard_clause.title}")
            report_lines.append(f"    â† {match.matched_clause.title}")
            if match.llm_decision:
                report_lines.append(f"    ì‹ ë¢°ë„: {match.llm_decision.confidence:.0%}")
        
        # ëˆ„ë½ëœ ì¡°ë¬¸
        report_lines.append(f"\n\n{'='*80}")
        report_lines.append("âŒ ëˆ„ë½ëœ ì¡°ë¬¸:")
        for clause in result.missing_clauses:
            report_lines.append(f"\n  [{clause.id}] {clause.title}")
            report_lines.append(f"    {clause.text[:100]}...")
        
        report_lines.append(f"\n{'='*80}")
        
        return {"report": "\n".join(report_lines)}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
