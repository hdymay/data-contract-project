"""
LLM Verification Service for Contract Clause Matching

This module provides LLM-based semantic verification to determine if two clauses
are semantically equivalent, even if they use different wording.
"""

import json
import logging
from typing import List, Tuple, Optional
from openai import AzureOpenAI

try:
    from backend.consistency_agent.node_1_clause_matching.models import ClauseData, VerificationDecision
    from backend.consistency_agent.node_1_clause_matching.config import config
except ImportError:
    from .models import ClauseData, VerificationDecision
    from .config import config

# Configure logging
logging.basicConfig(level=getattr(logging, config.LOG_LEVEL))
logger = logging.getLogger(__name__)


class LLMVerificationService:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì¡°ë¬¸ì˜ ì˜ë¯¸ë¡ ì  ì¼ì¹˜ ì—¬ë¶€ë¥¼ ê²€ì¦í•˜ëŠ” ì„œë¹„ìŠ¤
    
    Azure OpenAIì˜ GPT-4o ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸ê³¼ 
    ì‚¬ìš©ì ê³„ì•½ì„œ ì¡°ë¬¸ì´ ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.
    """
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    VERIFICATION_PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì˜ **ì˜ë¯¸ì  ìœ ì‚¬ì„±**ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‘ ê°œì˜ ê³„ì•½ì„œ í•­(clause)ì´ **ë¹„ìŠ·í•œ ë‚´ìš©**ì„ ë‹¤ë£¨ê³  ìˆëŠ”ì§€ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

**í•µì‹¬ í‰ê°€ ê¸°ì¤€: ì˜ë¯¸ì  ìœ ì‚¬ì„± (Semantic Similarity)**

ëª©ì ì€ "ì‚¬ìš©ì ê³„ì•½ì„œì— í‘œì¤€ ê³„ì•½ì„œì˜ ì´ ë‚´ìš©ì´ ë‹¤ë¤„ì§€ê³  ìˆëŠ”ê°€?"ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë²•ì  íš¨ë ¥ì˜ ì°¨ì´ëŠ” ë‚˜ì¤‘ ë‹¨ê³„ì—ì„œ íŒë‹¨í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” **ì£¼ì œì™€ ì˜ë¯¸ê°€ ìœ ì‚¬í•œì§€**ë§Œ íŒë‹¨í•˜ì„¸ìš”.

**íŒë‹¨ ì˜ˆì‹œ:**

âœ… **ìœ ì‚¬í•¨ (ì¼ì¹˜):**
- í‘œì¤€: "ë°ì´í„° ì œê³µ ë²”ìœ„ëŠ” ë³„ì§€1ì— ê¸°ì¬" â†” ì‚¬ìš©ì: "ì œê³µ ë°ì´í„°ëŠ” ë³„ë„ í•©ì˜ëœ ë²”ìœ„" 
  â†’ ë‘˜ ë‹¤ "ë°ì´í„° ë²”ìœ„ ì •ì˜"ë¥¼ ë‹¤ë£¸
  
- í‘œì¤€: "í’ˆì§ˆì„ ë³´ì¦í•œë‹¤" â†” ì‚¬ìš©ì: "í’ˆì§ˆ ìœ ì§€ë¥¼ ìœ„í•´ ë…¸ë ¥í•œë‹¤"
  â†’ ë‘˜ ë‹¤ "ë°ì´í„° í’ˆì§ˆ"ì„ ë‹¤ë£¸ (í‘œí˜„ì€ ë‹¤ë¥´ì§€ë§Œ ì£¼ì œ ë™ì¼)
  
- í‘œì¤€: "ë¶ˆê°€í•­ë ¥ ì‹œ ì±…ì„ ë©´ì œ" â†” ì‚¬ìš©ì: "ì²œì¬ì§€ë³€ ì‹œ ì±…ì„ ì—†ìŒ"
  â†’ ë‘˜ ë‹¤ "ë¶ˆê°€í•­ë ¥ ë©´ì±…"ì„ ë‹¤ë£¸

âŒ **ìœ ì‚¬í•˜ì§€ ì•ŠìŒ (ë¶ˆì¼ì¹˜):**
- í‘œì¤€: "ê¸ˆìœµê¸°ê´€ ê±°ë˜ì •ì§€ ì‹œ í•´ì§€" â†” ì‚¬ìš©ì: "ì§€ê¸‰ ë¶ˆì´í–‰ ì‹œ í•´ì§€"
  â†’ ë‘˜ ë‹¤ "í•´ì§€"ì§€ë§Œ í•´ì§€ ì‚¬ìœ ê°€ ì™„ì „íˆ ë‹¤ë¦„
  
- í‘œì¤€: "ë°ì´í„° ì œê³µìì˜ ê¶Œë¦¬ ë³´ì¦" â†” ì‚¬ìš©ì: "ë°ì´í„° ì´ìš©ìì˜ ì˜ë¬´"
  â†’ ì£¼ì²´ê°€ ë‹¤ë¥´ê³  ë‚´ìš©ë„ ë‹¤ë¦„
  
- í‘œì¤€: "ê°œì¸ì •ë³´ ë³´í˜¸ ì˜ë¬´" â†” ì‚¬ìš©ì: "ì¼ë°˜ ë°ì´í„° ë³´ì•ˆ ì¡°ì¹˜"
  â†’ ê°œì¸ì •ë³´ vs ì¼ë°˜ ë³´ì•ˆ (ë²”ìœ„ê°€ ë‹¤ë¦„)

**í‰ê°€ ì ˆì°¨:**

1. **í‘œì¤€ í•­ì´ ë‹¤ë£¨ëŠ” ì£¼ì œ íŒŒì•…**
   - ì´ í•­ì€ ë¬´ì—‡ì— ê´€í•œ ë‚´ìš©ì¸ê°€?
   - í•µì‹¬ í‚¤ì›Œë“œ: ë°ì´í„° ë²”ìœ„? ëŒ€ê°€ ì§€ê¸‰? ê³„ì•½ í•´ì§€? ì±…ì„ ë©´ì œ?

2. **ì‚¬ìš©ì í•­ì´ ë‹¤ë£¨ëŠ” ì£¼ì œ íŒŒì•…**
   - ì´ í•­ì€ ë¬´ì—‡ì— ê´€í•œ ë‚´ìš©ì¸ê°€?
   - í‘œì¤€ í•­ê³¼ ê°™ì€ ì£¼ì œë¥¼ ë‹¤ë£¨ëŠ”ê°€?

3. **ìœ ì‚¬ì„± íŒë‹¨**
   - ë‘ í•­ì´ **ê°™ì€ ì£¼ì œ/ë‚´ìš©**ì„ ë‹¤ë£¨ëŠ”ê°€?
   - í‘œí˜„ì´ ë‹¬ë¼ë„ **ì˜ë¯¸ê°€ ë¹„ìŠ·**í•œê°€?

**ì¤‘ìš” ì›ì¹™:**
1. **ì£¼ì œ ì¤‘ì‹¬ íŒë‹¨** - "ë¬´ì—‡ì— ê´€í•œ ë‚´ìš©ì¸ê°€?"
2. **í‘œí˜„ ì°¨ì´ í—ˆìš©** - ë¬¸êµ¬ê°€ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë¹„ìŠ·í•˜ë©´ ì¼ì¹˜
3. **ë²•ì  íš¨ë ¥ ì°¨ì´ëŠ” ë¬´ì‹œ** - "ë³´ì¦" vs "ë…¸ë ¥"ë„ ë‘˜ ë‹¤ í’ˆì§ˆ ê´€ë ¨ì´ë©´ ìœ ì‚¬
4. **ì£¼ì œê°€ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜** - ê°™ì€ ì¹´í…Œê³ ë¦¬ì—¬ë„ êµ¬ì²´ì  ë‚´ìš©ì´ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜

**í‘œì¤€ í•­ (Standard Clause):**
{standard_clause}

**ì‚¬ìš©ì í•­ (User Clause):**
{candidate_clause}

ìœ„ ë‘ í•­ì´ **ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬**í•œì§€ íŒë‹¨í•˜ê³ , ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

{{
    "is_match": true ë˜ëŠ” false,
    "confidence": 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ ì ìˆ˜,
    "reasoning": "ë‘ í•­ì´ ë‹¤ë£¨ëŠ” ì£¼ì œë¥¼ ê°ê° ì„¤ëª…í•˜ê³ , ìœ ì‚¬/ë¶ˆì¼ì¹˜ íŒë‹¨ ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œ"
}}

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

    def __init__(self, model: str = None, api_version: str = "2024-02-15-preview"):
        """
        LLM ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: config.AZURE_LLM_DEPLOYMENT)
            api_version: Azure OpenAI API ë²„ì „
        """
        self.model = model or config.AZURE_LLM_DEPLOYMENT
        self.api_version = api_version
        
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            config.validate()
            self.client = AzureOpenAI(
                api_key=config.AZURE_OPENAI_API_KEY,
                api_version=self.api_version,
                azure_endpoint=config.AZURE_ENDPOINT
            )
            logger.info(f"LLM Verification Service initialized with model: {self.model}")
        except Exception as e:
            logger.error(f"Failed to initialize Azure OpenAI client: {e}")
            raise
    
    def verify_clause_match(
        self, 
        standard_clause: ClauseData, 
        candidate_clause: ClauseData
    ) -> VerificationDecision:
        """
        ë‘ ì¡°ë¬¸ì´ ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œì§€ LLMìœ¼ë¡œ ê²€ì¦
        
        Args:
            standard_clause: í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸
            candidate_clause: ë¹„êµ ëŒ€ìƒ ì¡°ë¬¸
            
        Returns:
            VerificationDecision: ê²€ì¦ ê²°ê³¼ (ë§¤ì¹­ ì—¬ë¶€, ì‹ ë¢°ë„, ê·¼ê±°)
        """
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_verification_prompt(standard_clause, candidate_clause)
            
            # LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì„ ì •í™•í•˜ê²Œ ë¹„êµí•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
                max_tokens=500,
                response_format={"type": "json_object"}  # JSON ì‘ë‹µ ê°•ì œ
            )
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_llm_response(response)
            
            logger.debug(
                f"Verification result for clause {standard_clause.id}: "
                f"match={result.is_match}, confidence={result.confidence}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error during LLM verification: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜ë¡œ íŒë‹¨
            return VerificationDecision(
                is_match=False,
                confidence=0.0,
                reasoning=f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def verify_clause_match_batch(
        self,
        user_clause: ClauseData,
        standard_candidates: List[tuple],  # [(ClauseData, similarity), ...]
        min_confidence: float = 0.5
    ) -> List[VerificationDecision]:
        """
        í•œ ì‚¬ìš©ì ì¡°ë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ í‘œì¤€ í›„ë³´ë¥¼ í•œ ë²ˆì— ê²€ì¦ (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            user_clause: ì‚¬ìš©ì ê³„ì•½ì„œ ì¡°ë¬¸
            standard_candidates: [(í‘œì¤€ ì¡°ë¬¸, ìœ ì‚¬ë„), ...] ë¦¬ìŠ¤íŠ¸
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„
            
        Returns:
            List[VerificationDecision]: ê° í›„ë³´ì— ëŒ€í•œ ê²€ì¦ ê²°ê³¼
        """
        if not standard_candidates:
            return []
        
        user_text = user_clause.text_norm or user_clause.text
        
        # í›„ë³´ ì¡°ë¬¸ë“¤ í…ìŠ¤íŠ¸ êµ¬ì„±
        candidates_text = ""
        for i, (candidate, similarity) in enumerate(standard_candidates, 1):
            std_text = candidate.text_norm or candidate.text
            candidates_text += f"""
**í›„ë³´ {i}: {candidate.id}** (FAISS ìœ ì‚¬ë„: {similarity:.2f})
{std_text}

"""
        
        prompt = f"""ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì˜ **ì˜ë¯¸ì  ìœ ì‚¬ì„±**ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì‚¬ìš©ì ì¡°ë¬¸ ({user_clause.id}):**
{user_text}

**í‘œì¤€ ê³„ì•½ì„œ í›„ë³´ ì¡°ë¬¸ë“¤:**
{candidates_text}

ê° í‘œì¤€ í›„ë³´ ì¡°ë¬¸ì´ ì‚¬ìš©ì ì¡°ë¬¸ê³¼ **ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬**í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

**íŒë‹¨ ê¸°ì¤€:**
- ê°™ì€ ì£¼ì œ/ë‚´ìš©ì„ ë‹¤ë£¨ëŠ”ê°€?
- í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œê°€?
- ë²•ì  íš¨ë ¥ ì°¨ì´ëŠ” ë¬´ì‹œ (ì£¼ì œ ì¤‘ì‹¬ íŒë‹¨)
- **ì—¬ëŸ¬ í›„ë³´ê°€ ìœ ì‚¬í•  ìˆ˜ ìˆìŒ** (ì‚¬ìš©ì ì¡°ë¬¸ì´ ì—¬ëŸ¬ í‘œì¤€ ì¡°ë¬¸ì˜ ë‚´ìš©ì„ í¬í•¨í•  ìˆ˜ ìˆìŒ)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (ëª¨ë“  í›„ë³´ í¬í•¨):
{{
    "results": [
        {{
            "candidate_id": "í›„ë³´ 1 ID",
            "is_match": true/false,
            "confidence": 0.0~1.0,
            "reasoning": "íŒë‹¨ ê·¼ê±° (2-3ë¬¸ì¥)"
        }},
        {{
            "candidate_id": "í›„ë³´ 2 ID",
            "is_match": true/false,
            "confidence": 0.0~1.0,
            "reasoning": "íŒë‹¨ ê·¼ê±° (2-3ë¬¸ì¥)"
        }}
    ]
}}

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì„ ì •í™•í•˜ê²Œ ë¹„êµí•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=1500,
                response_format={"type": "json_object"}
            )
            
            result_json = json.loads(response.choices[0].message.content.strip())
            
            # ê²°ê³¼ë¥¼ VerificationDecision ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            decisions = []
            for result in result_json.get('results', []):
                decisions.append(VerificationDecision(
                    is_match=result.get('is_match', False),
                    confidence=float(result.get('confidence', 0.0)),
                    reasoning=result.get('reasoning', '')
                ))
            
            logger.debug(
                f"Batch verification: {user_clause.id} with {len(standard_candidates)} candidates, "
                f"matched: {sum(1 for d in decisions if d.is_match)}"
            )
            
            return decisions
            
        except Exception as e:
            logger.error(f"Error during batch LLM verification: {e}")
            # ì—ëŸ¬ ì‹œ ëª¨ë“  í›„ë³´ë¥¼ ë¶ˆì¼ì¹˜ë¡œ ë°˜í™˜
            return [
                VerificationDecision(
                    is_match=False,
                    confidence=0.0,
                    reasoning=f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                )
                for _ in standard_candidates
            ]
    
    def batch_verify(
        self, 
        pairs: List[Tuple[ClauseData, ClauseData]]
    ) -> List[VerificationDecision]:
        """
        ì—¬ëŸ¬ ì¡°ë¬¸ ìŒì„ ë°°ì¹˜ë¡œ ê²€ì¦ (ë ˆê±°ì‹œ)
        
        Args:
            pairs: (í‘œì¤€ ì¡°ë¬¸, í›„ë³´ ì¡°ë¬¸) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[VerificationDecision]: ê° ìŒì— ëŒ€í•œ ê²€ì¦ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, (standard_clause, candidate_clause) in enumerate(pairs):
            logger.info(f"Verifying pair {i+1}/{len(pairs)}")
            result = self.verify_clause_match(standard_clause, candidate_clause)
            results.append(result)
        
        retur
    
    def verify_missing_clause_forward_batch(
        self,
        standard_clause: ClauseData,
        user_candidates: List[tuple]  # [(ClauseData, similarity), ...]
    ) -> dict:
        """
        ëˆ„ë½ëœ í‘œì¤€ ì¡°ë¬¸ì„ Top-3 í›„ë³´ì™€ í•œ ë²ˆì— ë¹„êµ (ë°°ì¹˜ ì •ë°©í–¥ ê²€ì¦)
        
        Args:
            standard_clause: ëˆ„ë½ëœ í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸
            user_candidates: [(ì‚¬ìš©ì ì¡°ë¬¸, ìœ ì‚¬ë„), ...] ë¦¬ìŠ¤íŠ¸ (Top-3)
            
        Returns:
            dict: {
                'candidates': [ê° í›„ë³´ë³„ íŒë‹¨ ê²°ê³¼],
                'summary': ì¢…í•© ë¶„ì„ í…ìŠ¤íŠ¸
            }
        """
        standard_text = standard_clause.text_norm or standard_clause.text
        
        # í›„ë³´ ì¡°ë¬¸ë“¤ í…ìŠ¤íŠ¸ êµ¬ì„±
        candidates_text = ""
        for i, (candidate, similarity) in enumerate(user_candidates, 1):
            user_text = candidate.text_norm or candidate.text
            candidates_text += f"""
**í›„ë³´ {i}: {candidate.id}** (FAISS ìœ ì‚¬ë„: {similarity:.2f})
{user_text}

"""
        
        prompt = f"""ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ ë¶„ì„ ë° ë¦¬ìŠ¤í¬ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë¶„ì„ ëŒ€ìƒ:**
í‘œì¤€ ê³„ì•½ì„œì˜ "{standard_clause.id} ({standard_clause.title})" ì¡°ë¬¸ì´ ì‚¬ìš©ì ê³„ì•½ì„œì—ì„œ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.
ì´ ì¡°ë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ì ê³„ì•½ì„œ ì¡°ë¬¸ Top-3ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.
ê° í›„ë³´ê°€ í‘œì¤€ ì¡°ë¬¸ì˜ ë‚´ìš©ì„ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

**í‘œì¤€ ì¡°ë¬¸ ({standard_clause.id}):**
{standard_text}

**ì‚¬ìš©ì ê³„ì•½ì„œ í›„ë³´ ì¡°ë¬¸ (Top-3):**
{candidates_text}

---

### ğŸ’¡ **íŒë‹¨ ì§€ì¹¨**
1. **ë¶€ë¶„ ì¼ì¹˜(í‘œí˜„ ì°¨ì´í˜•)** â€“ í•µì‹¬ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ì¼ë¶€ ì¡°ê±´Â·ì ˆì°¨Â·ì˜ë¬´ê°€ ëˆ„ë½ë˜ê±°ë‚˜ í‘œí˜„ì´ ë‹¤ë¦„  
   (ì˜ˆ: 'í•˜ì—¬ì•¼ í•œë‹¤' â†’ 'í•  ìˆ˜ ìˆë‹¤', 'ì‚¬ì „ í†µì§€ ë° ì„œë©´ ë™ì˜' ì¤‘ ì¼ë¶€ë§Œ í¬í•¨)
2. **ë¬´ê´€** â€“ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ ì—†ìŒ
3. ë°˜ë“œì‹œ Top-3 í›„ë³´ ëª¨ë‘ì— ëŒ€í•´ íŒë‹¨í•˜ê³ , í‘œì¤€ì˜ í•µì‹¬ìš”ì†Œ ì¤‘ ì–´ë–¤ ë¶€ë¶„ì´ í¬í•¨/ëˆ„ë½ë˜ì—ˆëŠ”ì§€,  
   ê·¸ë¡œ ì¸í•œ ì ì¬ì  ë¦¬ìŠ¤í¬(ë²•ì Â·ìš´ì˜ì )ë¥¼ í•¨ê»˜ ì„¤ëª…í•  ê²ƒ.
4. confidence: 0.0~1.0 (0.6 â†‘ = ì˜ë¯¸ ìœ ì‚¬, 0.3 ~ 0.6 = ë¶€ë¶„ ìœ ì‚¬ / í‘œí˜„ ì°¨ì´í˜•, 0.3 â†“ = ë¬´ê´€)

---

### **ë¶„ì„ ìš”ì²­**
ê° í›„ë³´ ì¡°ë¬¸ì„ í‘œì¤€ ì¡°ë¬¸ê³¼ ë¹„êµí•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ì‘ì„± ê°€ì´ë“œ:**
1. **ê·¼ê±°(reasoning)**: 
   - **ë°˜ë“œì‹œ í›„ë³´ ì¡°ë¬¸ì˜ ì‹¤ì œ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©**í•˜ì—¬ ë¹„êµí•˜ì„¸ìš”
   - í‘œì¤€ ì¡°ë¬¸ì˜ í•µì‹¬ ìš”ì†Œ(ì˜ë¬´, ì¡°ê±´, ì ˆì°¨ ë“±)ë¥¼ íŒŒì•…í•˜ê³ , ê° í›„ë³´ê°€ ì´ë¥¼ ì–¼ë§ˆë‚˜ í¬í•¨í•˜ëŠ”ì§€ ì„œìˆ 
   - ì˜ˆì‹œ: "í›„ë³´ ì¡°ë¬¸ì€ 'ë°ì´í„° ì œê³µ ë²”ìœ„ëŠ” ë³„ë„ í˜‘ì˜'ë¼ê³  ëª…ì‹œí•˜ê³  ìˆì–´, í‘œì¤€ì˜ 'ë³„ì§€1ì— ê¸°ì¬' ë°©ì‹ê³¼ ìœ ì‚¬í•˜ë‚˜..."
   - ëˆ„ë½ëœ ë¶€ë¶„ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ (2-3ë¬¸ì¥ì˜ ì—°ê²°ëœ ë¬¸ë‹¨)

2. **ìœ„í—˜(risk)**: "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´..." í˜•ì‹ì˜ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‘ì„±í•˜ì„¸ìš”. ê³„ì•½ ì²´ê²°Â·ì´í–‰Â·ë¶„ìŸ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë¬¸ì œ ìƒí™©ì„ ì„¤ëª…í•˜ì„¸ìš”. (1-2ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì„œìˆ )

3. **ì¢…í•© ë¶„ì„(summary)**: 
   - Top-3 í›„ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•œ ê²°ê³¼ë¥¼ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±
   - **ê° í›„ë³´ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ëµíˆ ì¸ìš©**í•˜ë©´ì„œ ë¹„êµ
   - ì™œ ì´ í‘œì¤€ ì¡°ë¬¸ì´ ëˆ„ë½ìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª… (3-5ë¬¸ì¥ì˜ ì—°ê²°ëœ ë¬¸ë‹¨)

4. **ì „ì²´ ìœ„í—˜(overall_risk)**: "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´..." í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ì—¬, ê³„ì•½ì„œ ì „ì²´ ê´€ì ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë²•ì Â·ìš´ì˜ì  ìœ„í—˜ì„ ì‹œë‚˜ë¦¬ì˜¤ í˜•ì‹ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”. (2-3ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨)

5. **ê¶Œê³ (recommendation)**: ê° í›„ë³´ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ "~ì„ ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤" í˜•ì‹ìœ¼ë¡œ ëë‚˜ëŠ” ê¶Œê³ ì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”. (1-2ë¬¸ì¥)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (Top-3 í›„ë³´ ëª¨ë‘ í¬í•¨):
{{
    "candidates": [
        {{
            "candidate_id": "í›„ë³´ ì¡°ë¬¸ ID",
            "is_match": true/false,
            "confidence": 0.0~1.0,
            "match_type": "ë¶€ë¶„ ì¼ì¹˜(í‘œí˜„ ì°¨ì´í˜•)" | "ë¬´ê´€",
            "reasoning": "í›„ë³´ ì¡°ë¬¸ì˜ ì‹¤ì œ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©í•˜ë©° í‘œì¤€ ì¡°ë¬¸ê³¼ ë¹„êµ. ì˜ˆ: 'í›„ë³´ëŠ” \"[ì‹¤ì œ ë¬¸êµ¬]\"ë¼ê³  ëª…ì‹œí•˜ì—¬...' í˜•ì‹ìœ¼ë¡œ ì‘ì„± (2-3ë¬¸ì¥)",
            "risk": "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´ [êµ¬ì²´ì  ë¬¸ì œ ìƒí™©]ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ì¶”ê°€ ìœ„í—˜ ì„¤ëª…] (1-2ë¬¸ì¥)",
            "recommendation": "êµ¬ì²´ì  ê¶Œê³ ì‚¬í•­ì„ ì„œìˆ í•˜ê³  '~ì„ ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤'ë¡œ ë§ˆë¬´ë¦¬ (1-2ë¬¸ì¥)"
        }},
        {{
            "candidate_id": "í›„ë³´ 2 ì¡°ë¬¸ ID",
            "is_match": true/false,
            "confidence": 0.0~1.0,
            "match_type": "ë¶€ë¶„ ì¼ì¹˜(í‘œí˜„ ì°¨ì´í˜•)" | "ë¬´ê´€",
            "reasoning": "í›„ë³´ ì¡°ë¬¸ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©í•˜ë©° ë¹„êµ (2-3ë¬¸ì¥)",
            "risk": "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´... ì‹œë‚˜ë¦¬ì˜¤ (1-2ë¬¸ì¥)",
            "recommendation": "~ì„ ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤ (1-2ë¬¸ì¥)"
        }},
        {{
            "candidate_id": "í›„ë³´ 3 ì¡°ë¬¸ ID",
            "is_match": true/false,
            "confidence": 0.0~1.0,
            "match_type": "ë¶€ë¶„ ì¼ì¹˜(í‘œí˜„ ì°¨ì´í˜•)" | "ë¬´ê´€",
            "reasoning": "í›„ë³´ ì¡°ë¬¸ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©í•˜ë©° ë¹„êµ (2-3ë¬¸ì¥)",
            "risk": "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´... ì‹œë‚˜ë¦¬ì˜¤ (1-2ë¬¸ì¥)",
            "recommendation": "~ì„ ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤ (1-2ë¬¸ì¥)"
        }}
    ],
    "summary": "Top-3 í›„ë³´ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ëµíˆ ì¸ìš©í•˜ë©° ì¢…í•© ë¹„êµ. ì™œ ì´ í‘œì¤€ ì¡°ë¬¸ì´ ëˆ„ë½ìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€ ì„¤ëª… (3-5ë¬¸ì¥ì˜ ì—°ê²°ëœ ë¬¸ë‹¨)",
    "overall_risk": "ì´ ì¡°í•­ì´ ì—†ìœ¼ë©´ [êµ¬ì²´ì  ì‹œë‚˜ë¦¬ì˜¤]ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³„ì•½ ì²´ê²°Â·ì´í–‰Â·ë¶„ìŸ ì‹œ ì–´ë–¤ ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ  (2-3ë¬¸ì¥ì˜ ì—°ê²°ëœ ë¬¸ë‹¨)"
}}

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì„ ì •í™•í•˜ê²Œ ë¹„êµ ë¶„ì„í•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=1500,
                response_format={"type": "json_object"}
            )
            
            result_json = json.loads(response.choices[0].message.content.strip())
            
            logger.debug(
                f"Batch forward verification: {standard_clause.id} with {len(user_candidates)} candidates"
            )
            
            return result_json
            
        except Exception as e:
            logger.error(f"Error during batch forward LLM verification: {e}")
            # ì—ëŸ¬ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            return {
                'candidates': [
                    {
                        'candidate_id': cand[0].id,
                        'is_match': False,
                        'confidence': 0.0,
                        'match_type': 'ë¬´ê´€',
                        'reasoning': f'ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
                    }
                    for cand in user_candidates
                ],
                'summary': f'ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }
    
    def verify_missing_clause_forward(
        self,
        standard_clause: ClauseData,
        user_candidate: ClauseData
    ) -> VerificationDecision:
        """
        ëˆ„ë½ëœ í‘œì¤€ ì¡°ë¬¸ì´ ì‚¬ìš©ì ì¡°ë¬¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (ì •ë°©í–¥) - ë ˆê±°ì‹œ
        
        Args:
            standard_clause: ëˆ„ë½ëœ í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸
            user_candidate: ì‚¬ìš©ì ê³„ì•½ì„œ í›„ë³´ ì¡°ë¬¸
            
        Returns:
            VerificationDecision: ê²€ì¦ ê²°ê³¼
        """
        standard_text = standard_clause.text_norm or standard_clause.text
        user_text = user_candidate.text_norm or user_candidate.text
        
        prompt = f"""ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì§ˆë¬¸:** í‘œì¤€ ì¡°ë¬¸ "{standard_clause.id}"ì˜ ì˜ë¯¸ì™€ ë™ì¼í•˜ê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œ í¬í•¨ëœ ë‚´ìš©ì´ ì‚¬ìš©ì ì¡°ë¬¸ì— ìˆëŠ”ê°€?

**í‘œì¤€ ì¡°ë¬¸ ({standard_clause.id}):**
{standard_text}

**ì‚¬ìš©ì ì¡°ë¬¸ ({user_candidate.id}):**
{user_text}

**íŒë‹¨ ê¸°ì¤€:**
1. **ì™„ì „ ì¼ì¹˜**: ì‚¬ìš©ì ì¡°ë¬¸ì´ í‘œì¤€ ì¡°ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì™„ì „íˆ í¬í•¨
2. **ë¶€ë¶„ ì¼ì¹˜**: ì‚¬ìš©ì ì¡°ë¬¸ì´ í‘œì¤€ ì¡°ë¬¸ì˜ ì¼ë¶€ ë‚´ìš©ë§Œ í¬í•¨ (í‘œí˜„ ì°¨ì´ í¬í•¨)
3. **ë¬´ê´€**: ì‚¬ìš©ì ì¡°ë¬¸ì´ í‘œì¤€ ì¡°ë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ ì—†ìŒ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "is_match": true (ì™„ì „/ë¶€ë¶„ ì¼ì¹˜) ë˜ëŠ” false (ë¬´ê´€),
    "confidence": 0.0~1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„,
    "reasoning": "íŒë‹¨ ê·¼ê±°ë¥¼ ëª…í™•íˆ í’ë¶€í•˜ê²Œ ì„¤ëª… (ì™œ ì¼ì¹˜/ë¶ˆì¼ì¹˜ì¸ì§€, ì–´ë–¤ ë¶€ë¶„ì´ ìœ ì‚¬/ë‹¤ë¥¸ì§€)"
}}

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì„ ì •í™•í•˜ê²Œ ë¹„êµí•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=500,
                response_format={"type": "json_object"}
            )
            
            result = self._parse_llm_response(response)
            
            logger.debug(
                f"Forward verification: {standard_clause.id} -> {user_candidate.id}: "
                f"match={result.is_match}, confidence={result.confidence:.2f}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error during forward LLM verification: {e}")
            return VerificationDecision(
                is_match=False,
                confidence=0.0,
                reasoning=f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def explain_mismatch(
        self, 
        standard_clause: ClauseData, 
        candidate_clause: ClauseData
    ) -> str:
        """
        ë¶ˆì¼ì¹˜ ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…
        
        Args:
            standard_clause: í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸
            candidate_clause: ë¹„êµ ëŒ€ìƒ ì¡°ë¬¸
            
        Returns:
            str: ë¶ˆì¼ì¹˜ ì´ìœ  ì„¤ëª…
        """
        # ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë²• ì ìš©: text_norm ì‚¬ìš©
        standard_text = standard_clause.text_norm or standard_clause.text
        candidate_text = candidate_clause.text_norm or candidate_clause.text
        
        prompt = f"""ë‹¤ìŒ ë‘ ê³„ì•½ì„œ ì¡°ë¬¸ì´ ì™œ ë‹¤ë¥¸ì§€ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:

**í‘œì¤€ ì¡°ë¬¸:**
{standard_text}

**ë¹„êµ ëŒ€ìƒ ì¡°ë¬¸:**
{candidate_text}

ì°¨ì´ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ì–´ë–¤ ë¶€ë¶„ì´ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ëª…í™•íˆ í•´ì£¼ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°ë¬¸ì˜ ì°¨ì´ì ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            explanation = response.choices[0].message.content.strip()
            return explanation
            
        except Exception as e:
            logger.error(f"Error generating mismatch explanation: {e}")
            return f"ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _create_verification_prompt(
        self, 
        standard_clause: ClauseData, 
        candidate_clause: ClauseData
    ) -> str:
        """
        ê²€ì¦ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            standard_clause: í‘œì¤€ ê³„ì•½ì„œ ì¡°ë¬¸
            candidate_clause: ë¹„êµ ëŒ€ìƒ ì¡°ë¬¸
            
        Returns:
            str: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        # ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë²• ì ìš©: text_norm ì‚¬ìš© (// êµ¬ë¶„ì í¬í•¨)
        standard_text = standard_clause.text_norm or standard_clause.text
        candidate_text = candidate_clause.text_norm or candidate_clause.text
        
        # ë³„ì§€ ì°¸ì¡° ê°ì§€ ë° ì²˜ë¦¬
        if "[ë³„ì§€" in standard_text:
            appendix_note = "\n\n**ì°¸ê³ :** ì´ ì¡°ë¬¸ì€ ë³„ì§€ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤. ë³„ì§€ëŠ” ì‚¬ìš©ìê°€ ì‘ì„±í•´ì•¼ í•˜ëŠ” ì–‘ì‹ì´ë¯€ë¡œ, ì‚¬ìš©ì ì¡°ë¬¸ì— í•´ë‹¹ ë‚´ìš©ì´ë‚˜ í˜•ì‹ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë³„ì§€ ì°¸ì¡°ê°€ ìˆë‹¤ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ë¶€ë¶„ì ìœ¼ë¡œ ì¼ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            standard_text += appendix_note
        
        return self.VERIFICATION_PROMPT_TEMPLATE.format(
            standard_clause=standard_text,
            candidate_clause=candidate_text
        )
    
    def _parse_llm_response(self, response) -> VerificationDecision:
        """
        LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ VerificationDecision ê°ì²´ ìƒì„±
        
        Args:
            response: Azure OpenAI API ì‘ë‹µ
            
        Returns:
            VerificationDecision: íŒŒì‹±ëœ ê²€ì¦ ê²°ê³¼
        """
        try:
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            result_dict = json.loads(content)
            
            # VerificationDecision ê°ì²´ ìƒì„±
            decision = VerificationDecision(
                is_match=result_dict.get("is_match", False),
                confidence=float(result_dict.get("confidence", 0.0)),
                reasoning=result_dict.get("reasoning", "")
            )
            
            return decision
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.error(f"Response content: {content}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜ë¡œ íŒë‹¨
            return VerificationDecision(
                is_match=False,
                confidence=0.0,
                reasoning=f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
            )
        except Exception as e:
            logger.error(f"Error parsing LLM response: {e}")
            return VerificationDecision(
                is_match=False,
                confidence=0.0,
                reasoning=f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            )
