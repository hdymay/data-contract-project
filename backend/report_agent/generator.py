"""
Report Generator for Contract Verification Results

ì´ ëª¨ë“ˆì€ ê³„ì•½ì„œ ê²€ì¦ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ë³´ê³ ì„œë¡œ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, List
from collections import defaultdict
from openai import AzureOpenAI

from backend.shared.models import VerificationResult, ClauseData, MatchResult
from backend.consistency_agent.node_1_clause_matching.config import config

# Configure logging
logger = logging.getLogger(__name__)


class ReportGenerator:
    """
    ê²€ì¦ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±ê¸°
    
    í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ê³„ì•½ì„œ ê²€ì¦ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, output_dir: Optional[Path] = None):
        """
        ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            output_dir: ë³´ê³ ì„œ ì €ìž¥ ë””ë ‰í† ë¦¬ (Noneì¸ ê²½ìš° data/reports ì‚¬ìš©)
        """
        if output_dir is None:
            output_dir = Path("data/reports")
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.llm_client = AzureOpenAI(
            api_key=config.AZURE_OPENAI_API_KEY,
            api_version=config.AZURE_OPENAI_API_VERSION,
            azure_endpoint=config.AZURE_OPENAI_ENDPOINT
        )
        
        logger.info(f"Report Generator initialized with output_dir: {self.output_dir}")
    
    def _group_matches_by_user_article(self, match_results: List[MatchResult]) -> Dict[str, List[MatchResult]]:
        """
        ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‚¬ìš©ìž ê³„ì•½ì„œì˜ ì¡°ë³„ë¡œ ê·¸ë£¹í•‘
        
        Args:
            match_results: ë§¤ì¹­ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì¡°ë³„ë¡œ ê·¸ë£¹í•‘ëœ ë§¤ì¹­ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        grouped = defaultdict(list)
        
        for match in match_results:
            if match.is_matched and match.matched_clause:
                # ì‚¬ìš©ìž ì¡°ë¬¸ IDì—ì„œ ì¡° ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "ì œ1ì¡° ì¡°ë³¸ë¬¸" -> "ì œ1ì¡°")
                user_clause_id = match.matched_clause.id
                article_num = user_clause_id.split()[0] if ' ' in user_clause_id else user_clause_id
                
                # ì¡° ì œëª© ì¶”ì¶œ
                article_title = match.matched_clause.title
                
                # í‚¤ëŠ” "ì¡°ë²ˆí˜¸ (ì œëª©)" í˜•ì‹
                key = f"{article_num} ({article_title})"
                grouped[key].append(match)
        
        return dict(grouped)
    
    def _analyze_article_matching_pattern(self, matches: List[MatchResult]) -> Dict:
        """
        í•œ ì¡°ì˜ ë§¤ì¹­ íŒ¨í„´ ë¶„ì„ (LLM ì‚¬ìš©)
        
        Args:
            matches: í•œ ì¡°ì— ì†í•œ ë§¤ì¹­ ê²°ê³¼ë“¤
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ê¸°ë³¸ í†µê³„
        total_items = len(matches)
        avg_confidence = sum(m.llm_decision.confidence for m in matches if m.llm_decision) / total_items if total_items > 0 else 0
        
        # ë§¤ì¹­ëœ í‘œì¤€ ì¡°í•­ë“¤ ì¶”ì¶œ
        std_articles = defaultdict(int)
        for match in matches:
            std_article_num = match.standard_clause.id.split()[0] if ' ' in match.standard_clause.id else match.standard_clause.id
            std_articles[std_article_num] += 1
        
        # ë§¤ì¹­ ìœ í˜• íŒë‹¨
        if len(std_articles) == 1:
            matching_type = "ì™„ì „ ì¼ëŒ€ì¼ ë§¤ì¹­" if total_items == list(std_articles.values())[0] else "ë¶€ë¶„ ë§¤ì¹­"
        else:
            matching_type = "í†µí•© ë§¤ì¹­"
        
        # LLMì—ê²Œ ë²•ì  ë¶„ì„ ìš”ì²­
        legal_analysis = self._generate_legal_analysis(matches, matching_type)
        
        return {
            "total_items": total_items,
            "avg_confidence": avg_confidence,
            "std_articles": dict(std_articles),
            "matching_type": matching_type,
            "legal_analysis": legal_analysis
        }
    
    def _generate_legal_analysis(self, matches: List[MatchResult], matching_type: str) -> str:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë²•ì  ë¶„ì„ ìƒì„±
        
        Args:
            matches: ë§¤ì¹­ ê²°ê³¼ë“¤
            matching_type: ë§¤ì¹­ ìœ í˜•
        
        Returns:
            ë²•ì  ë¶„ì„ í…ìŠ¤íŠ¸
        """
        # ì‚¬ìš©ìž ì¡° ì •ë³´
        user_article = matches[0].matched_clause.title if matches else ""
        user_article_id = matches[0].matched_clause.id.split()[0] if matches and ' ' in matches[0].matched_clause.id else ""
        
        # í‘œì¤€ ì¡°í•­ ì •ë³´
        std_info = []
        for match in matches:
            std_id = match.standard_clause.id.split()[0] if ' ' in match.standard_clause.id else match.standard_clause.id
            std_title = match.standard_clause.title
            std_info.append(f"{std_id}({std_title})")
        
        prompt = f"""ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ë‹¤ìŒ ë§¤ì¹­ ê²°ê³¼ì— ëŒ€í•œ ë²•ì  ë¶„ì„ì„ 2-3ë¬¸ìž¥ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”.

**ì‚¬ìš©ìž ê³„ì•½ì„œ ì¡°í•­:** {user_article_id} ({user_article})
**ë§¤ì¹­ëœ í‘œì¤€ ì¡°í•­:** {', '.join(std_info)}
**ë§¤ì¹­ ìœ í˜•:** {matching_type}
**ë§¤ì¹­ëœ í•­ëª© ìˆ˜:** {len(matches)}ê°œ

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ì™œ ì´ëŸ° ë§¤ì¹­ íŒ¨í„´ì´ ë‚˜íƒ€ë‚¬ëŠ”ì§€ ì„¤ëª…
2. ì‚¬ìš©ìž ê³„ì•½ì„œì™€ í‘œì¤€ ê³„ì•½ì„œì˜ êµ¬ì¡°ì  ì°¨ì´
3. ë²•ì  ì˜ë¯¸ë‚˜ ëª…í™•ì„± ì¸¡ë©´ì—ì„œì˜ ì°¨ì´ì 

**ì¶œë ¥ í˜•ì‹:** 
â€¢ (ì²« ë²ˆì§¸ ë¬¸ìž¥)
â€¢ (ë‘ ë²ˆì§¸ ë¬¸ìž¥)
â€¢ (ì„¸ ë²ˆì§¸ ë¬¸ìž¥)

ê° ë¬¸ìž¥ì€ bullet pointë¡œ ì‹œìž‘í•˜ê³ , ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìž‘ì„±í•˜ì„¸ìš”."""

        try:
            response = self.llm_client.chat.completions.create(
                model=config.AZURE_OPENAI_DEPLOYMENT_NAME,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            analysis = response.choices[0].message.content.strip()
            return analysis
            
        except Exception as e:
            logger.error(f"LLM ë²•ì  ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            return "â€¢ ë¶„ì„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    

    def generate_text_report_with_llm(
        self,
        result: VerificationResult,
        output_path: Optional[str] = None
    ) -> str:
        """
        LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹ ë³´ê³ ì„œ ìƒì„± (ì¡°ë³„ ë§¤ì¹­ ìš”ì•½ í¬í•¨)
        
        Args:
            result: ê²€ì¦ ê²°ê³¼
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì¸ ê²½ìš° ìžë™ ìƒì„±)
        
        Returns:
            ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
        """
        logger.info("Generating LLM-based text report with article summaries...")
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.output_dir / f"verification_report_{timestamp}.txt"
        else:
            output_path = Path(output_path)
        
        # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
        report_lines = []
        
        # í—¤ë”
        report_lines.append("=" * 80)
        report_lines.append("ðŸ“‹ ë‚´ ê³„ì•½ì„œ ê²€ì¦ ê²°ê³¼")
        report_lines.append("My Contract Verification Report")
        report_lines.append("=" * 80)
        report_lines.append("")
        
        # ê²€ì¦ ì¼ì‹œ
        report_lines.append(f"ê²€ì¦ ì¼ì‹œ: {result.verification_date.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
        report_lines.append("")
        
        # ê²€ì¦ ê²°ê³¼ ìš”ì•½
        report_lines.append("-" * 80)
        report_lines.append("ðŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        report_lines.append("-" * 80)
        report_lines.append(f"ë‚´ ê³„ì•½ì„œ ì¡°ë¬¸ ìˆ˜: {result.total_user_clauses}ê°œ")
        report_lines.append(f"í‘œì¤€ ê³„ì•½ì„œì™€ ë§¤ì¹­ëœ ì¡°ë¬¸: {result.matched_clauses}ê°œ")
        report_lines.append(f"í‘œì¤€ ê³„ì•½ì„œì— ì—†ëŠ” ì¡°ë¬¸: {result.total_user_clauses - result.matched_clauses}ê°œ")
        report_lines.append("")
        report_lines.append(f"ê²€ì¦ ì™„ë£Œìœ¨: {result.verification_rate:.2f}%")
        report_lines.append("")
        
        # ì¡°ë³„ ë§¤ì¹­ ìš”ì•½
        report_lines.append("-" * 80)
        report_lines.append("ðŸ“˜ ë‚´ ê³„ì•½ì„œ ì¡°ë³„ ë§¤ì¹­ ìš”ì•½")
        report_lines.append("-" * 80)
        report_lines.append("")
        
        # ë§¤ì¹­ ê²°ê³¼ë¥¼ ì¡°ë³„ë¡œ ê·¸ë£¹í•‘
        grouped_matches = self._group_matches_by_user_article(result.match_results)
        
        for article_key, matches in sorted(grouped_matches.items()):
            # ì¡°ë³„ ë¶„ì„
            analysis = self._analyze_article_matching_pattern(matches)
            
            # í‘œì¤€ ì¡°í•­ ì •ë³´
            std_articles_str = ", ".join([f"ì œ{k.replace('ì œ', '').replace('ì¡°', '')}ì¡°" for k in analysis['std_articles'].keys()])
            
            # ìš”ì•½ í—¤ë”
            report_lines.append(f"ðŸ“˜ [ìš”ì•½] {article_key} â€” í‘œì¤€ {std_articles_str}ì™€ ë§¤ì¹­ ({analysis['matching_type']})")
            report_lines.append("â”€" * 60)
            
            # ë²•ì  ë¶„ì„
            report_lines.append(analysis['legal_analysis'])
            report_lines.append("")
            
            # í†µê³„ ì •ë³´
            if analysis['matching_type'] == "ì™„ì „ ì¼ëŒ€ì¼ ë§¤ì¹­":
                report_lines.append(f"ðŸ“Š ì‚¬ìš©ìž {article_key.split('(')[0]}ì˜ ëª¨ë“  í•­({analysis['total_items']}ê°œ)ì´ í‘œì¤€ {std_articles_str}ì™€ ë§¤ì¹­ë¨")
            elif analysis['matching_type'] == "ë¶€ë¶„ ë§¤ì¹­":
                # ì „ì²´ í•­ ìˆ˜ ê³„ì‚° (ì´ê±´ ê·¼ì‚¬ì¹˜)
                report_lines.append(f"ðŸ“Š ì‚¬ìš©ìž {article_key.split('(')[0]}ì˜ ì¼ë¶€ í•­({analysis['total_items']}ê°œ)ì´ í‘œì¤€ {std_articles_str}ì™€ ë§¤ì¹­ë¨")
            else:  # í†µí•© ë§¤ì¹­
                report_lines.append(f"ðŸ“Š ë§¤ì¹­ ìƒì„¸:")
                for std_art, count in analysis['std_articles'].items():
                    std_num = std_art.replace('ì œ', '').replace('ì¡°', '')
                    report_lines.append(f"  â€¢ ì œ{std_num}ì¡°: {count}ê°œ í•­ ë§¤ì¹­")
            
            report_lines.append(f"  â€¢ í‰ê·  ì‹ ë¢°ë„: {analysis['avg_confidence']:.1%}")
            report_lines.append("â”€" * 60)
            report_lines.append("")
        
        # í•­ë³„ ìƒì„¸ ë§¤ì¹­ ê²°ê³¼
        matched_clauses = [r for r in result.match_results if r.is_matched]
        
        report_lines.append("-" * 80)
        report_lines.append("âœ… ë‚´ ê³„ì•½ì„œ í•­ë³„ ìƒì„¸ ë§¤ì¹­ ê²°ê³¼")
        report_lines.append("-" * 80)
        report_lines.append("")
        
        if matched_clauses:
            report_lines.append(f"ì´ {len(matched_clauses)}ê°œ í•­ì´ í‘œì¤€ ê³„ì•½ì„œì™€ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
            
            for i, match_result in enumerate(matched_clauses, 1):
                user_clause = match_result.matched_clause
                std_clause = match_result.standard_clause
                
                report_lines.append(f"[{i}] {user_clause.display_title}")
                report_lines.append(f"    ID: {user_clause.id}")
                report_lines.append(f"    ë‚´ìš©: {user_clause.text[:120]}{'...' if len(user_clause.text) > 120 else ''}")
                report_lines.append("")
                report_lines.append(f"    âœ“ ë§¤ì¹­: í‘œì¤€ {std_clause.display_title} ({std_clause.id})")
                
                if match_result.llm_decision:
                    report_lines.append(f"       ì‹ ë¢°ë„: {match_result.llm_decision.confidence:.0%}")
                    report_lines.append(f"       íŒë‹¨: {match_result.llm_decision.reasoning[:180]}{'...' if len(match_result.llm_decision.reasoning) > 180 else ''}")
                
                report_lines.append("")
        else:
            report_lines.append("âš ï¸ ë§¤ì¹­ëœ í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
            report_lines.append("")
        
        # ëˆ„ë½ëœ ì¡°ë¬¸
        report_lines.append("-" * 80)
        report_lines.append("âŒ í‘œì¤€ ê³„ì•½ì„œì— ìžˆì§€ë§Œ ë‚´ ê³„ì•½ì„œì— ì—†ëŠ” ì¡°ë¬¸")
        report_lines.append("-" * 80)
        report_lines.append("")
        
        if result.missing_clauses:
            report_lines.append(f"ì´ {len(result.missing_clauses)}ê°œì˜ í‘œì¤€ ì¡°ë¬¸ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
            
            for i, clause in enumerate(result.missing_clauses, 1):
                report_lines.append(f"{i}. {clause.display_title}")
                report_lines.append(f"   í‘œì¤€ ì¡°ë¬¸ ID: {clause.id}")
                
                # ì¡°ë¬¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                text_preview = clause.text[:150]
                if len(clause.text) > 150:
                    text_preview += "..."
                report_lines.append(f"   ë‚´ìš©: {text_preview}")
                report_lines.append("")
        else:
            report_lines.append("âœ“ ëª¨ë“  í‘œì¤€ ì¡°ë¬¸ì´ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤!")
            report_lines.append("")
        
        # ê¶Œìž¥ì‚¬í•­
        report_lines.append("-" * 80)
        report_lines.append("âš ï¸ ê¶Œìž¥ì‚¬í•­")
        report_lines.append("-" * 80)
        report_lines.append("")
        
        if result.missing_clauses:
            # ì¤‘ìš”í•œ ëˆ„ë½ ì¡°ë¬¸ ì‹ë³„
            important_keywords = ['ëª©ì ', 'ì •ì˜', 'ì†í•´ë°°ìƒ', 'ë¹„ë°€ìœ ì§€', 'ê³„ì•½ê¸°ê°„', 'í•´ì§€']
            important_missing = [
                c for c in result.missing_clauses 
                if any(keyword in c.display_title for keyword in important_keywords)
            ]
            
            if important_missing:
                report_lines.append("ðŸ”´ ì¤‘ìš”: ë‹¤ìŒ í•„ìˆ˜ ì¡°í•­ë“¤ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤:")
                report_lines.append("")
                for clause in important_missing[:5]:
                    report_lines.append(f"  â€¢ {clause.display_title} ì¶”ê°€ ê¶Œìž¥")
                report_lines.append("")
            
            report_lines.append("ðŸ’¡ ê°œì„  ì œì•ˆ:")
            report_lines.append(f"  â€¢ ì´ {len(result.missing_clauses)}ê°œì˜ í‘œì¤€ ì¡°ë¬¸ ê²€í†  í•„ìš”")
            report_lines.append("  â€¢ ë²•ì  ë¦¬ìŠ¤í¬ ìµœì†Œí™”ë¥¼ ìœ„í•´ ëˆ„ë½ëœ ì¡°ë¬¸ ì¶”ê°€ ê³ ë ¤")
            report_lines.append("")
        else:
            report_lines.append("âœ“ ê³„ì•½ì„œê°€ í‘œì¤€ ì¡°ë¬¸ì„ ìž˜ ë°˜ì˜í•˜ê³  ìžˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
        
        # í‘¸í„°
        report_lines.append("=" * 80)
        report_lines.append("ë³´ê³ ì„œ ë")
        report_lines.append("=" * 80)
        
        # íŒŒì¼ ì €ìž¥
        report_content = "\n".join(report_lines)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(report_content)
        
        logger.info(f"LLM-based text report saved to: {output_path}")
        
        return str(output_path)
    
    def generate_text_report(
        self,
        result: VerificationResult,
        output_path: Optional[str] = None
    ) -> str:
        """
        í…ìŠ¤íŠ¸ í˜•ì‹ ë³´ê³ ì„œ ìƒì„± (ì‚¬ìš©ìž ê³„ì•½ì„œ ì¤‘ì‹¬)
        
        Args:
            result: ê²€ì¦ ê²°ê³¼
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì¸ ê²½ìš° ìžë™ ìƒì„±)
        
        Returns:
            ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
        """
        # LLM ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return self.generate_text_report_with_llm(result, output_path)
    
    def format_missing_clauses(self, missing_clauses: list[ClauseData]) -> str:
        """
        ëˆ„ë½ëœ ì¡°ë¬¸ì„ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·
        
        Args:
            missing_clauses: ëˆ„ë½ëœ ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            í¬ë§·ëœ ë¬¸ìžì—´
        """
        if not missing_clauses:
            return "ëˆ„ë½ëœ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
        
        lines = []
        
        for i, clause in enumerate(missing_clauses, 1):
            lines.append(f"{i}. {clause.display_title}")
            lines.append(f"   ID: {clause.id}")
            lines.append(f"   íƒ€ìž…: {clause.type}")
            
            # ì¡°ë¬¸ ë‚´ìš© (ì²˜ìŒ 200ìžë§Œ í‘œì‹œ)
            text_preview = clause.text[:200]
            if len(clause.text) > 200:
                text_preview += "..."
            
            lines.append(f"   ë‚´ìš©: {text_preview}")
            lines.append("")
        
        return "\n".join(lines)